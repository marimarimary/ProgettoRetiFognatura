{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os              #Operating System\n",
    "import math            #funzioni matematiche\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "#from datetime import datetime #\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt #Plot\n",
    "\n",
    "# Strumenti di Statistica (ECDF, GUMBEL, MinimiQuadrati)\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from scipy.stats import genextreme,gumbel_r, norm\n",
    "from scipy.optimize import least_squares\n",
    "from numpy import linspace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.getcwd() != '/home/fanda/Dropbox/doc/trento/Tesi/data':\n",
    "    os.chdir(\"./data\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = ! zenity --file-selection  --separator=, --file-filter=*.xls\n",
    "print(str(file[0]))\n",
    "dati = pd.read_excel(str(file[0]) ) # si può usare anche read_csv\n",
    "\n",
    "dati.columns = ['year','15m', 'date15h',\n",
    "                       '30m', 'date30m',\n",
    "                       '45m', 'date45m',\n",
    "                       '1h',  'date1h',\n",
    "                       '3h',  'date3h',\n",
    "                       '6h',  'date6h',\n",
    "                       '12h', 'date12h',\n",
    "                       '24h', 'date24h',\n",
    "                       '1g',  'date1g',\n",
    "                       '2g',  'date2g',\n",
    "                       '3g',  'date3g',\n",
    "                       '4g',  'date4g',\n",
    "                       '5g',  'date5g'     ] # Rinomina gli indici delle colonne(va bene per il sito meteotrentino.it)\n",
    "dati = dati[ dati.year.notnull() ]            # elimino le righe senza informazioni\n",
    "dati = dati[ dati.year != \"anno\" ]            # elimino le righe senza informazioni\n",
    "#dati.year = [ int(i)  for i in dati.year ]    # trasformo da float a integer gli anni\n",
    "dati = dati.set_index('year')                 # imposto l'anno come indice delle righe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tempi di interesse\n",
    "seleziono quali tempi di pioggia sono interesse dell'analisi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = [10,20,100] # Tempi di ritorno\n",
    "\n",
    "times_rain = ['15m', '30m', '45m', '1h', '3h', '6h', '12h', '24h', '1g', '2g', '3g', '4g', '5g', ]\n",
    "\n",
    "dati = dati.apply(pd.to_numeric, errors='coerce') # trasforma tutti i numeri in float\n",
    "\n",
    "times_toremove = [] # rimuovo i tempi nulli\n",
    "for t in times_rain:\n",
    "    #print(t)\n",
    "    if dati[t].isnull().all():\n",
    "        #print('Tutti i valori di ' + t + ' sono nulli')\n",
    "        times_toremove.append(t)\n",
    "for t in times_toremove:\n",
    "    times_rain.remove(t)\n",
    "    \n",
    "dati = dati[times_rain]\n",
    "dati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodi di Fitting\n",
    "\n",
    "### Media e deviazione standard delle misurazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = pd.DataFrame(dati.mean(), index = times_rain, columns=[\"mean\"])\n",
    "fit['std'] = dati.std()\n",
    "fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodo dei Momenti\n",
    "\n",
    "Il metodo dei momenti si riduce alla risoluzione di:\n",
    "\\begin{equation}\n",
    "\\left\\{\n",
    "\\begin{array}{l}\n",
    "\\mu_H = b \\gamma + a \\\\\n",
    "\\sigma^2_H = b^2  \\frac{\\pi^2}{6}\n",
    "\\end{array}\n",
    "\\right.\n",
    "\\end{equation}\n",
    "dove $a$ e $b$ sono i parametri da stimare $\\mu_H$ è la media del campioni di dati e $\\sigma_H$ è la deviazione standard dei medesimi dati. \n",
    "Dalla seconda equazione si ricava:\n",
    "\\begin{equation}\n",
    "b = \\frac{\\sqrt{6}}{\\pi} \\sigma_H\n",
    "\\end{equation}\n",
    "che, sostituito nella prima equazione, dà:\n",
    "\\begin{equation}\n",
    "a = \\mu_H -\\frac{\\sqrt{6}\\ \\gamma}{\\pi} \\sigma_H \n",
    "\\end{equation}\n",
    "dove $\\gamma$ è la costante di Eulero-Mascheroni pari a 0.577"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MetodoMomenti(data):\n",
    "    mean = data.mean()\n",
    "    sd   = data.std()\n",
    "    Mascheroni = 0.577215664901532860606512090 # numero di Mascheroni\n",
    "    return [mean - math.sqrt(6) / math.pi * Mascheroni * sd,  \n",
    "            math.sqrt(6) / math.pi * sd]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodo della Massima Verosimiglianza\n",
    "Ricordiamo l'espressione della famiglia parametrica di curve di Gumbel:\n",
    " $$P[H<h;a,b] = exp\\left(-exp\\left(-\\frac{h-a}{b}\\right)\\right) $$\n",
    "\n",
    "Il metodo della massima verosimiglianza calcola i valori dei parametri \n",
    "per cui  la probabilità congiunta di ottenere una serie di dati  $\\{h_1, \\cdot \\cdot, h_n \\}$ è massima:\n",
    "\\begin{equation}\n",
    "{\\rm argmax}_{a,b} P[\\{h_1, \\cdot \\cdot, h_n \\};a,b] = {\\rm argmax}_{a,b} \\prod_i^n P[h_i;a,b]\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In python è un metodo già implementato attraverso \n",
    "#la funzione gumbel_r.fit determina i parametri a,b\n",
    "def Metodo_Massima_Verosimiglianza(data):  \n",
    "    param = gumbel_r.fit(data) # distribution fitting\n",
    "    return param\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodo dei Minimi Quadrati\n",
    "Il metodo dei minimi quadrati è implementato nel software come un problema di ottimizzazione in (a,b) di un sistema non linare:\n",
    "\\begin{equation} \n",
    "\\delta^2(a,b) = \\sum_i^N (ECDF_i-P[h_i;a,b])^2 \\to \\rm min \n",
    "\\end{equation}\n",
    "dove $ECDF_i$ sono i valori sperimentali e $P[h_i;a,b]$ sono i valori attesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel(x,a,b):\n",
    "    return np.exp(-np.exp(-(x-a)/b)) # Valori attesi\n",
    "\n",
    "def fun(x,t,y): # least_squares vuole x come incognite\n",
    "    a =x[0]\n",
    "    b = x[1]\n",
    "    return gumbel(t,a,b) - y\n",
    "\n",
    "def Metodo_Minimi_Quadrati(dat):\n",
    "    t = sorted(dat) \n",
    "    y = ECDF(t)(t) # Valori Sperimentali\n",
    "    res_lsq = least_squares(fun, #funzione\n",
    "                            x0=[dat.mean(),10.], #punti iniziali\n",
    "                            args=(t, y),\n",
    "                            )\n",
    "    return res_lsq.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applico i 3 modelli di fitting ai vari dati\n",
    "\n",
    "mm, mv, mq = [], [], []\n",
    "\n",
    "for i in times_rain:\n",
    "    dt = dati[i].dropna()\n",
    "    mm.append(MetodoMomenti(dt))\n",
    "    mv.append(Metodo_Massima_Verosimiglianza(dt))\n",
    "    mq.append(Metodo_Minimi_Quadrati(dt))\n",
    "    \n",
    "mm = pd.DataFrame(mm, columns=[\"mm_a\",\"mm_b\"], index=times_rain)\n",
    "mv = pd.DataFrame(mv, columns=[\"mv_a\",\"mv_b\"], index=times_rain)\n",
    "mq = pd.DataFrame(mq, columns=[\"mq_a\",\"mq_b\"], index=times_rain)\n",
    "\n",
    "fit = pd.concat([fit,mm,mv,mq], axis=1, sort=False)\n",
    "fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test di Pearson\n",
    "\n",
    "Il test di perarson è un test non parametrico che consiste nel \n",
    "- suddividere il campo di probabilità in $k$ parti\n",
    "- derivarne una suddivisione del dominio\n",
    "- contare il numero di dati in ciascun intervallo \n",
    "- nel caso di $k$ parti uguali vautare la funzione:\n",
    "\n",
    "$$ \\chi^2 = \\frac{k}{n} \\sum_{j=1}^k (N_j - \\frac{n}{k})^2 $$\n",
    "\n",
    "\n",
    "\n",
    "* Valuazione sulla bontà del risultato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def x_test(dat, a, b, tr, k): \n",
    "    dt = dat.dropna()\n",
    "    #print(dt)\n",
    "    n = len(dt)\n",
    "    #print(\"lh: \",lh)\n",
    "    # suddivido il campo in k parti uguali\n",
    "    q  = [ 1/k * (i+1) for i in range(k) ]\n",
    "    #print(\"q: \",q)\n",
    "    rv = gumbel_r( loc= a, scale= b ) \n",
    "    r  = ECDF(dt)(rv.ppf(q))          # [lista] numero di valori sperimentali in ogni quantile\n",
    "    #print(\"r: \",r)\n",
    "    oss = n * r\n",
    "    #print(\"o0: \",o0)\n",
    "    N  = oss - np.append([0],np.delete(oss,-1)) # numero di osservazioni in ogni campo\n",
    "    #print(\"o: \",o)\n",
    "    e  = [1/k * n for i in range(k)]  # caso ottimale di valori egualmente distribuiti\n",
    "    #print(\"e: \",e)\n",
    "    return ((N-e)**2/e).sum()  \n",
    "\n",
    "#Chi TEST\n",
    "chi = []\n",
    "for time in times_rain:\n",
    "    elem=[]\n",
    "    for metodo in ['mm', 'mv', 'mq']:\n",
    "        a = fit.loc[time, metodo+'_a']\n",
    "        b = fit.loc[time, metodo+'_b']\n",
    "        # print(a,b)\n",
    "        test = x_test(dati[time], a, b, time, 5) \n",
    "        elem.append( round(test, 3) )\n",
    "    chi.append(elem)\n",
    "    \n",
    "chi = pd.DataFrame(chi, columns=[\"chi_mm\", \"chi_mv\", \"chi_mq\"], \n",
    "                   index=times_rain)\n",
    "fit = pd.concat([fit,chi], axis=1, sort=False)\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determina la migliore approsimazione (quella con il chi^2 minore) e \n",
    "m_best = chi.T.idxmin()\n",
    "for i in times_rain:\n",
    "    m_best[i] = m_best[i].replace('chi_','')\n",
    "\n",
    "a = []\n",
    "b = []\n",
    "for i in times_rain:\n",
    "    best = m_best.loc[i]\n",
    "    best = best.replace('chi_','')\n",
    "        \n",
    "    if \"mm\" in best :\n",
    "        a.append(fit.loc[i,'mm_a'])\n",
    "        b.append(fit.loc[i,'mm_b'])\n",
    "    elif \"mv\" in best:\n",
    "        a.append(fit.loc[i,'mv_a'])\n",
    "        b.append(fit.loc[i,'mv_b'])\n",
    "    elif \"mq\" in best:\n",
    "        a.append(fit.loc[i,'mq_a'])\n",
    "        b.append(fit.loc[i,'mq_b'])\n",
    "    else: \n",
    "        a.append('ERRORE!')\n",
    "        b.append('ERRORE!')\n",
    "        \n",
    "\n",
    "#print(a,b)\n",
    "#print(m_best)\n",
    "\n",
    "fit['best'] = m_best\n",
    "fit['a'] = a\n",
    "fit['b'] = b\n",
    "\n",
    "fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grafici delle distribuzioni\n",
    "Andiamo a disegnare le curve di gumbel ottenute dai vari metodi di fitting, andando a ingrossare quella con il punteggio del  test di Pearson migliore. Disegneremo in seguito le curve di gumbel scelte e la densità di probabilità."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel(x,a,b):\n",
    "    return np.exp(-np.exp(-(x-a)/b))\n",
    "#plt.rc('xtick', labelsize=12) #Questi comandi globali\n",
    "#plt.rc('ytick', labelsize=12) #Questi sono comandi globali  \n",
    "#plt.rc(\"savefig\",dpi=300)\n",
    "\n",
    "for i in times_rain:\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    space=np.linspace(dati[i].min(),dati[i].max(),100)\n",
    "    df['h']  = space \n",
    "    df['mm'] = gumbel(space, fit.loc[i,'mm_a'], fit.loc[i,'mm_b'])\n",
    "    df['mv'] = gumbel(space, fit.loc[i,'mv_a'], fit.loc[i,'mv_b'])\n",
    "    df['mq'] = gumbel(space, fit.loc[i,'mq_a'], fit.loc[i,'mq_b'])\n",
    "    \n",
    "    list_width=[1,1,1]\n",
    "    best = fit.loc[i, 'best']\n",
    "    if   'mm' in best:\n",
    "        list_width[0]=2.5\n",
    "    elif 'mv' in best:\n",
    "        list_width[1]=2.5\n",
    "    elif 'mq' in best:\n",
    "        list_width[2]=2.5\n",
    "      \n",
    "    graf = df.plot( \n",
    "                 'h' ,    'mm' , linewidth=list_width[0], label='mm')\n",
    "    graf.plot(df['h'], df['mv'], linewidth=list_width[1], label='mv')\n",
    "    graf.plot(df['h'], df['mq'], linewidth=list_width[2], label='mq')\n",
    "    \n",
    "    # Sovrappongo i Punti Sperimentali\n",
    "    x = dati[i].dropna()\n",
    "    \n",
    "    graf.plot(x,ECDF(x)(x),'.')\n",
    "    \n",
    "    #Tabella con i parametri di gumbel\n",
    "\n",
    "    table=pd.DataFrame()\n",
    "    table['a'] = fit.loc[ i, ['mm_a','mv_a','mq_a']].values.tolist()\n",
    "    table['b'] = fit.loc[ i, ['mm_b','mv_b','mq_b']].values.tolist()\n",
    "    table['c'] = fit.loc[ i, ['chi_mm','chi_mv','chi_mq']].values.tolist()\n",
    "    table=table.round(2)\n",
    "    \n",
    "    graf.table(cellText=table.values.tolist(), \n",
    "               fontsize=10,                 \n",
    "               #colWidths = [.15,.15,.15],\n",
    "               rowLabels=['mm','mv','mq'],\n",
    "               colLabels=['a','b','chi'],\n",
    "               #colLoc='center', loc='bottom',\n",
    "               bbox=[.6, 0.05, .35, .3],\n",
    "              )\n",
    "\n",
    "    \n",
    "    graf.legend(loc='best')\n",
    "    title='Curve di gubel per pioggia di '+i\n",
    "    graf.set_title(title, size=18)\n",
    "    graf.set_xlabel('Altezza pioggia [mm]')\n",
    "    graf.set_ylabel('P[H<h]')\n",
    "    \n",
    "    fig = graf.get_figure()\n",
    "    fig.savefig('gumbel_fit' + i + '.png', dpi = 300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico delle curve ottimali per i vari tempi di pioggia\n",
    "\n",
    "space=np.linspace(dati.min()[0],dati.max()[-1],100)\n",
    "\n",
    "gb = pd.DataFrame()\n",
    "\n",
    "for i in times_rain:\n",
    "    gb[i] = gumbel(space, fit.loc[i,'a'], fit.loc[i,'b'])\n",
    "\n",
    "gb.index=space\n",
    "gb\n",
    "\n",
    "plt=gb.plot()\n",
    "\n",
    "for i in times_rain: \n",
    "    x = dati[i].dropna()\n",
    "    plt.plot(x, ECDF(x)(x), '.')\n",
    "\n",
    "## Assi\n",
    "plt.set_title('Distribuzione di  probabilità di Gumbel, Cumulate', size=12)\n",
    "plt.set_xlabel('Altezza pioggia [mm]')\n",
    "plt.set_ylabel('P[H<h]')\n",
    "fig = plt.get_figure()\n",
    "fig.savefig(file[0] + '.Gumbel.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gumbel_dens(x,a,b):\n",
    "    z = (x-a) / b\n",
    "    return 1/b*np.exp( -z - np.exp( -z ))\n",
    "\n",
    "gb_dens = pd.DataFrame()\n",
    "space=np.linspace(dati.min()[0],dati.max()[-1],100)\n",
    "for i in times_rain:\n",
    "    gb_dens[i] = gumbel_dens(space, fit.loc[i,'a'], fit.loc[i,'b'])\n",
    "    \n",
    "gb_dens.index=space\n",
    "gb_dens\n",
    "\n",
    "plt = gb_dens.plot()\n",
    "\n",
    "plt.set_title('Distribuzione di Gumbel, densità di probabilità', size=12)\n",
    "plt.set_xlabel('Altezza pioggia [mm]')\n",
    "plt.set_ylabel('P[h]') ## Chiedere al professore la corretta etichetta\n",
    "#plt.get_figure().savefig('GumbelDensità.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linee Segnalatrici di Possibilità Pluviometrica\n",
    "Si va ora a interpolare i punti dei quantili con un prefissato tempo di ritorno,\n",
    "per le varie durate di pioggia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qtls(a,b,tr):\n",
    "    qu=1-1/tr\n",
    "    rv1h=gumbel_r(loc=a,scale=b)\n",
    "    return rv1h.ppf(qu) #Percent point function\n",
    "\n",
    "pts = []\n",
    "for tr in TR:\n",
    "    a = []\n",
    "    for i in times_rain:\n",
    "        a.append(qtls(fit.loc[i,'a'], fit.loc[i,'b'],tr))\n",
    "    pts.append(a)\n",
    "\n",
    "pts=pd.DataFrame(pts, index=TR, columns=times_rain).T\n",
    "pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grafico delle curve ottimali per i vari tempi di pioggia\n",
    "#\n",
    "#space=np.linspace(dati.min()[0],dati.max()[-1],1000)\n",
    "#\n",
    "#gb = pd.DataFrame()\n",
    "#\n",
    "#for i in times_rain:\n",
    "#    gb[i] = gumbel(space, fit.loc[i,'a'], fit.loc[i,'b'])\n",
    "#\n",
    "#gb.index=space\n",
    "#gb\n",
    "#\n",
    "#plt=gb.plot()\n",
    "#\n",
    "#for tr in TR: \n",
    "#    x = pts[tr]\n",
    "#    y = [1-1/tr] *len(x)\n",
    "#    plt.plot(x, y, '.', label = 'TR=' + str(tr) + ' anni')\n",
    "#plt.legend()\n",
    "#\n",
    "## I punti devono stare sulle curve\n",
    "#\n",
    "### Assi\n",
    "#plt.set_title('Curve probabilità di Gumbel', size=16)\n",
    "#plt.set_xlabel('Altezza pioggia [mm]')\n",
    "#plt.set_ylabel('P[H<h]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le curve di possibilità pluviometrica, sono rette nel piano bilogaritmico. Dovremo determinare i parametri a(Tr) e n\n",
    "$$ h(t_p, Tr) = a(T_r) t_p^n$$\n",
    "$$\\log h(t_p, Tr) = \\log a(T_r) + n \\log t_p $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parm_prox(x,y):\n",
    "    # Least squares polynomial fit\n",
    "    a=np.polyfit(np.log(x), np.log(y), 1) \n",
    "    return (a[0], np.exp(a[1]))\n",
    "\n",
    "times_rain_numeric = []\n",
    "\n",
    "for i in times_rain: # Trasformo i minuti in ore\n",
    "    if 'm' in i:\n",
    "        i = i.replace('m','')\n",
    "        i = float(i)\n",
    "        i = i / 60\n",
    "    elif 'g' in i:\n",
    "        i = i.replace('g','')\n",
    "        i = float(i)\n",
    "        i = i * 24\n",
    "    elif 'h' in i:\n",
    "        i = i.replace('h','')\n",
    "        i = float(i)\n",
    "    times_rain_numeric.append(i)\n",
    "\n",
    "fnl =  []\n",
    "for tr in TR:\n",
    "    fnl.append(parm_prox(x=times_rain_numeric,y=pts[tr]))\n",
    "    \n",
    "fnl = pd.DataFrame(fnl, columns=[\"n\",\"a\"], index=TR)\n",
    "#\n",
    "fnl.to_latex(file[0] +'LSPP.tex') #coefficenti a, n della curva di possibilità"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le Linee Segnalatrici di Possibilità Pluviometrica per tempi di ritorno di anni prendono le seguenti forme:\n",
    "\n",
    "$$ h(t, tr) = a t^{n}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = times_rain_numeric\n",
    "\n",
    "def h(t,a,n):\n",
    "    return a*t**n\n",
    "\n",
    "ddf = pd.DataFrame()\n",
    "\n",
    "for tr in TR:\n",
    "    height = h(space, fnl.loc[tr,'a'], fnl.loc[tr,'n'])\n",
    "    ddf[tr] = height\n",
    "    \n",
    "ddf.index = space \n",
    "ddf\n",
    "\n",
    "plt = ddf.plot()\n",
    "#plt.show()\n",
    "## Assi\n",
    "plt.set_title('Curve probabilità Pluviometrica', size=16)\n",
    "plt.set_xlabel('Altezza pioggia [mm]')\n",
    "plt.set_ylabel('Tempo di Pioggia [h]')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt_log = ddf.plot()\n",
    "\n",
    "plt_log.grid(True,)\n",
    "#plt_log.set_xticks([1,5,10,50,100,500])\n",
    "\n",
    "plt_log.plot(ddf, '.')\n",
    "plt_log.set_yscale('log')\n",
    "plt_log.set_xscale('log')\n",
    "## Assi\n",
    "plt_log.set_title('Linee di probabilità Pluviometrica', size=16)\n",
    "plt_log.set_xlabel('Altezza pioggia [mm]')\n",
    "plt_log.set_ylabel('Tempo di Pioggia [h]')\n",
    "\n",
    "#Tabella con i parametri di gumbel\n",
    "table=pd.DataFrame()\n",
    "table['a'] = fnl.loc[ :,'a' ].values.tolist()\n",
    "table['n'] = fnl.loc[ :,'n' ].values.tolist()\n",
    "table=table.round(3)\n",
    "   \n",
    "plt_log.table(cellText=table.values.tolist(), \n",
    "           fontsize=10  ,               \n",
    "          #colWidths = [.15,.15,.15],\n",
    "           rowLabels=TR,\n",
    "           colLabels=['a','n'],\n",
    "          #colLoc='center', loc='bottom',\n",
    "           bbox=[.62,.1,.28,.28],\n",
    "           )\n",
    "fig = plt_log.get_figure()\n",
    "fig.savefig(file[0] + '.LSPP.png', dpi = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Htot = []\n",
    "Junit = []\n",
    "\n",
    "for time in times_rain_numeric:\n",
    "    Htime = []\n",
    "    Jtime = []\n",
    "    for tr in TR:\n",
    "        a = fnl.loc[ tr,'a' ]\n",
    "        n = fnl.loc[ tr,'n' ]\n",
    "        Htime.append(a * time ** n)\n",
    "        Jtime.append(a * time ** (n-1)) # intensità in mm/hr\n",
    "    Htot.append(Htime)\n",
    "    Junit.append(Jtime)\n",
    "\n",
    "Htot = pd.DataFrame(Htot, index = times_rain, columns = TR)\n",
    "Junit = pd.DataFrame(Junit, index = times_rain, columns = TR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Htot.to_latex(file[0] +'Hpioggia.tex')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Junit.to_latex(file[0] +'Jpioggia.tex')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produco i file per le timeseries in EPA_SWMMM\n",
    "\n",
    "os.chdir('../timeseries/')\n",
    "\n",
    "for tr in TR:\n",
    "    for t in times_rain_numeric:\n",
    "        timeRain = times_rain[times_rain_numeric.index(t)]\n",
    "        t = t * 60  # trasformo in minuti\n",
    "        j = Junit.loc[timeRain,tr] # altezza di pioggia unitaria\n",
    "        clock = 1.\n",
    "        day0 = 1\n",
    "        f = open('TR' + str(tr)+'_t'+timeRain+'.dat', 'w')\n",
    "        \n",
    "        while clock <= t:\n",
    "            day  = int(clock/1440)\n",
    "            hour = int((clock - day * 1440)/60)\n",
    "            minute = clock - hour*60 - day * 1440\n",
    "            day = day + day0\n",
    "            \n",
    "            print(\"01/%02d/2020    %02d:%02d    %5f\" % (day, hour, minute, j), file = f)\n",
    "            clock +=1\n",
    "        f.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modifico il file .inp in modo che presenti tutti le timeseries\n",
    "import swmmio, shutil\n",
    "from swmmio.utils.modify_model import replace_inp_section\n",
    "from swmmio import create_dataframeINP\n",
    "\n",
    "baseline = swmmio.Model(r'../inp_file/rovereto.inp')\n",
    "#TIMESERIES = create_dataframeINP(baseline.inp.path,'[TIMESERIES]')\n",
    "\n",
    "list = []\n",
    "\n",
    "for tr in TR:\n",
    "    for t in times_rain_numeric:\n",
    "        timeRain = times_rain[times_rain_numeric.index(t)]\n",
    "        t = t * 60  # trasformo in minuti\n",
    "        #h = Junit.loc[timeRain,tr] # altezza di pioggia unitaria\n",
    "        #clock = 1.\n",
    "        #day0 = 1\n",
    "        name = 'TR' + str(tr) + '_t' + timeRain\n",
    "        list.append(name+ '        FILE \"../timeseries/' + name +'.dat\"')\n",
    "df = pd.DataFrame(list)\n",
    "df.columns = ['[TIMESERIES]']\n",
    "df\n",
    "\n",
    "# Creo nuovo inp file con un con le timeseries modificate\n",
    "newfilepath = os.path.join('../inp_file/' + baseline.inp.name + \"_\" + 'mod' + '.inp')\n",
    "shutil.copyfile(baseline.inp.path, newfilepath)\n",
    "replace_inp_section(newfilepath, '[TIMESERIES]', df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
